import argparse
import asyncio
import json
import logging
from typing import AsyncGenerator, Optional

import aiohttp

DEFAULT_MODEL_NAME = "llama3.1"
DEFAULT_API_URL = "http://localhost:11434/api/generate"


class LocalI:
    """
    A class to interact with the AI model server.

    Args:
        model_name (str): The name of the AI model to use.
        api_url (str): The URL of the AI model server
    """

    def __init__(self, model_name: str, api_url: str):
        self.model_name = model_name
        self.api_url = api_url
        self._session: Optional[aiohttp.ClientSession] = None

    async def __aenter__(self) -> 'LocalI':
        self._session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        if self._session:
            await self._session.close()

    async def generate_text(self, prompt: str) -> AsyncGenerator[str, None]:
        """
        Generate text based on the given prompt using the AI model server.

        Args:
            prompt (str): The prompt to generate text based on.

        Yields:
            AsyncGenerator[str, None]: A generator of text chunks generated by the AI model server.
        """

        if not self._session:
            raise RuntimeError("Session not initialized. Use 'async with' context manager.")

        data = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": True
        }

        try:
            async with self._session.post(self.api_url, json=data) as response:
                response.raise_for_status()
                async for line in response.content:
                    if line:
                        try:
                            json_line = json.loads(line)
                            if 'response' in json_line:
                                yield json_line['response']
                        except json.JSONDecodeError:
                            logging.error(f"Error decoding JSON: {line.decode('utf-8')}")
        except aiohttp.ClientError as e:
            logging.error(f"HTTP request failed: {e}")
        except Exception as e:
            logging.error(f"Unexpected error: {e}")


def parse_arguments() -> argparse.Namespace:
    """
    Parse command line arguments.

    Returns:
        argparse.Namespace: Parsed arguments.
    """
    parser = argparse.ArgumentParser(description="AI Assistant")
    parser.add_argument("--model", default=DEFAULT_MODEL_NAME, help="Model name to use")
    parser.add_argument("--url", default=DEFAULT_API_URL, help="API URL")
    return parser.parse_args()


async def main() -> None:
    """
    The main function to interact with the AI model server.
    """
    args = parse_arguments()

    try:
        async with LocalI(args.model, args.url) as assistant:
            while True:
                user_input = await asyncio.to_thread(input, "Enter your prompt (or 'quit' to exit): ")
                if user_input.lower() == 'quit':
                    break

                print("Assistant: ", end="", flush=True)
                async for text_chunk in assistant.generate_text(user_input):
                    print(text_chunk, end="", flush=True)
                print()  # New line after the complete response
    except KeyboardInterrupt:
        print("\nExiting...")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())
